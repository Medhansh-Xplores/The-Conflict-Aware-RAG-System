# ğŸŒŒ NebulaGears: Conflict-Aware RAG System  
### Google Gemini Flash + ChromaDB + Role-Based Policy Resolution

This repository implements a **Conflict-Aware Retrieval-Augmented Generation (RAG)** system capable of answering internal company policy questions even when the underlying documents contain **conflicting rules**.  
Using **Google Gemini Flash**, **Google text embeddings**, and a **local ChromaDB vector store**, the system ensures that employees receive **role-appropriate, citation-backed, and fully justified answers**.

This project was built to pass the assignment scenario:

> **â€œI just joined as a new intern. Can I work from home?â€**  
Even though general employees may work remotely, interns *cannot*, and the system must correctly cite the **Intern FAQ**.

---

# ğŸ“ Repository Structure

```
nebula-rag-conflict-aware/
â”‚
â”œâ”€â”€ step1_prepare_data.py
â”œâ”€â”€ step2_build_vectorstore.py
â”œâ”€â”€ step3_retrieve.py
â”œâ”€â”€ step4_answer.py
â”‚
â”œâ”€â”€ main.py
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â”‚
â””â”€â”€ intern_query_screenshot.png
    
```

---

# ğŸš€ Pipeline Overview (Detailed)

This project is intentionally split into **four modular steps** for clarity and correctness.

---

## ğŸŸ¦ **Step 1 â€” Data Preparation**  
**File:** `step1_prepare_data.py`

This step transforms raw policy documents into a structured dataset.

### It performs:
- Text cleaning (removes extra spaces, noise)
- Chunking into RAG-friendly segments
- Metadata attachment:
  - `roles` (e.g., intern, manager, all_employees)
  - `policy_type` (handbook, update, FAQ)
  - `date`
  - `source_filename`
- Exports all chunks to **prepared_docs.jsonl**

**Why this matters:**  
RAG pipelines cannot operate efficiently on raw text. Metadata is essential for conflict resolution.

---

## ğŸŸ¦ **Step 2 â€” Vector Store Creation**  
**File:** `step2_build_vectorstore.py`

This step creates the semantic index used for retrieval.

### Responsibilities:
- Load `prepared_docs.jsonl`
- Generate embeddings using **Google `text-embedding-004`**
- Create a **persistent ChromaDB** instance
- Store embeddings, text chunks, and metadata

**Why this matters:**  
ChromaDB acts as the **local knowledge base** for all semantic search operations.

---

## ğŸŸ¦ **Step 3 â€” Conflict-Aware Retrieval**  
**File:** `step3_retrieve.py`

This is the heart of the system.  
Instead of returning the document with the highest cosine similarity, this step applies a **Conflict-Aware Ranking Layer**.

### ğŸ” Step 3 Logic Includes:

#### 1ï¸âƒ£ Cosine Similarity  
Standard semantic similarity based on text embeddings.

#### 2ï¸âƒ£ **Role Boost (Most Important)**  
If the document applies to the userâ€™s role:

```
score *= 1.6
```

This ensures:
- Intern FAQs override policies for general employees  
- Manager updates override employee handbooks  
- Role-specific rules always win

#### 3ï¸âƒ£ **Specificity Boost**  
Policies applying to fewer roles are more authoritative:

```
specificity_boost = 1 + (2 / number_of_roles)
```

Example:
- Intern-only FAQ (1 role) â†’ highest specificity  
- Handbook (all employees) â†’ lowest specificity

#### 4ï¸âƒ£ **Recency Boost**  
Newer policies take precedence:

```
recency_boost = 1 + (year - 2023) * 0.05
```

#### 5ï¸âƒ£ **Final Scoring Formula**

```
final_score =
    cosine_sim Ã— role_boost Ã— specificity_boost Ã— recency_boost
```

**Result:**  
For the intern query, **Document C (Intern FAQ)** always ranks highest.

---

## ğŸŸ¦ **Step 4 â€” Final Answer Generation**  
**File:** `step4_answer.py`

This step produces the final employee-facing answer using **Google Gemini Flash**.

### It generates:
- **Final policy ruling**
- **One citation**
- **Direct quote** from the source
- **Reason why this document overrides others**
- **Explanation of rejected documents**

### Example Output:

```
FINAL RULING:
Interns cannot work from home. You are required to be in the office 5 days a week.

CITATION:
intern_onboarding_faq.txt

QUOTE:
"Interns are required to be in the office 5 days a week..."

WHY THIS DOC WAS CHOSEN:
It is the only policy written specifically for interns.

OTHER DOCUMENTS DISAGREED:
- employee_handbook_v1.txt: Applies to all employees.
- manager_updates_2024.txt: Applies to full-time hybrid workers.
```

---

# â–¶ï¸ **How to Run the Pipeline**

## 1ï¸âƒ£ Install dependencies
```
pip install -r requirements.txt
```

## 2ï¸âƒ£ Set your Google API Key
```python
import os
os.environ["GOOGLE_API_KEY"] = "YOUR_API_KEY"
```

## 3ï¸âƒ£ Run steps individually
```
python step1_prepare_data.py
python step2_build_vectorstore.py
python step3_retrieve.py
python step4_answer.py
```

## 4ï¸âƒ£ Or run the entire pipeline:
```
python main.py
```

---

# ğŸ“¸ **Required Screenshot**

```

![Intern Query Output](/mnt/data/93afdd42-5cff-4412-b46d-08c064b32b23.png)

```

---

# ğŸ’° **Cost Analysis (Required)**

### â­ Embedding Cost â€” 10,000 Documents
Assuming 200 tokens/doc:

```
10,000 Ã— 200 = 2,000,000 tokens
Embedding cost = 2M / 1,000 Ã— $0.00002 = $0.04 (one-time)
```

### â­ LLM Query Cost â€” 5,000 Queries/Day
Assuming 150 tokens output:

```
750,000 tokens/day
22,500,000 tokens/month
LLM Cost = 22.5M / 1,000 Ã— $0.00005 = $1.12/month
```

### ğŸ’µ **Total Monthly Cost â‰ˆ $1.20**

This makes the system extremely affordable at scale.

---

# ğŸ **Conclusion**

This system:

- Resolves conflicting documents  
- Applies role-aware prioritization  
- Uses local embeddings + ChromaDB  
- Produces transparent, cited answers  
- Is extremely cost-efficient  
- Satisfies every requirement of the assignment  

It ensures the correct policy is always selected - even when documents contradict each other.

---

